{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pipelines.inverted_ve_pipeline import create_image_grid\n",
    "from pipelines.pipeline_stable_diffusion_xl import StableDiffusionXLPipeline\n",
    "from utils import init_latent, memory_efficient\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cpu\":\n",
    "    torch_dtype = torch.float32\n",
    "else:\n",
    "    torch_dtype = torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_number_list(n):\n",
    "    return list(range(n + 1))\n",
    "\n",
    "\n",
    "def create_nested_list(t):\n",
    "    return [[0, t]]\n",
    "\n",
    "\n",
    "def create_prompt(style_name):\n",
    "    pre_prompt_dicts = {\n",
    "        \"kids drawing\": (\n",
    "            \"kids drawing of {prompt}. crayon, colored pencil, marker\",\n",
    "            \"\",\n",
    "        ),\n",
    "        \"self portrait\": (\"{prompt} of van gogh\", \"\"),\n",
    "        \"Sunflowers\": (\"{prompt} of van gogh\", \"\"),\n",
    "        \"The kiss\": (\"{prompt} of gustav klimt\", \"\"),\n",
    "        \"Vitruvian Man\": (\"{prompt} of leonardo da vinci\", \"\"),\n",
    "        \"Weeping woman\": (\"{prompt} of pablo picasso\", \"\"),\n",
    "        \"The scream\": (\"{prompt} of edvard munch\", \"\"),\n",
    "        \"The starry night\": (\"{prompt} of van gogh\", \"\"),\n",
    "        \"Starry night over the rhone\": (\"{prompt} of van gogh\", \"\"),\n",
    "        \"MOVIE\": (\"{prompt} movie poster\", \"\"),\n",
    "    }\n",
    "\n",
    "    if style_name in pre_prompt_dicts.keys():\n",
    "        return pre_prompt_dicts[style_name]\n",
    "    else:\n",
    "        return (\"{prompt}\", \"\")  # base_prompt, negative_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Arguments:\n",
    "    tar_obj: str = \"a dog and a man\" # target object\n",
    "    guidance_scale: float = 7.0\n",
    "    output_num: int = 4\n",
    "    activate_step: int = 50\n",
    "    results_dir: str = \"./results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDIMScheduler\n",
    "\n",
    "\n",
    "args = Arguments()\n",
    "tar_seeds = create_number_list(args.output_num)\n",
    "activate_step_indices = create_nested_list(args.activate_step)\n",
    "\n",
    "\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"RunDiffusion/Juggernaut-X-v10\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    variant=\"fp16\",\n",
    ")\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "str_activate_layer, str_activate_step = pipe.activate_layer(\n",
    "    activate_layer_indices=[[0, 0], [128, 140]],\n",
    "    attn_map_save_steps=[],\n",
    "    activate_step_indices=activate_step_indices,\n",
    "    use_shared_attention=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import load_image\n",
    "\n",
    "\n",
    "img_path = args.img_path\n",
    "tar_obj = args.tar_obj\n",
    "guidance_scale = args.guidance_scale\n",
    "\n",
    "with torch.no_grad():\n",
    "    hf_dataset_base_url = \"https://huggingface.co/datasets/GoGiants1/TMDBEval500/resolve/main/TMDBEval500/images/\"\n",
    "    real_img = load_image(hf_dataset_base_url + '1.jpg')\n",
    "\n",
    "    style_name = \"MOVIE\"\n",
    "    latents = []\n",
    "\n",
    "    base_prompt, negative_prompt = create_prompt(style_name)\n",
    "    ref_prompt = base_prompt.replace(\"{prompt}\", style_name)\n",
    "    inf_prompt = base_prompt.replace(\"{prompt}\", tar_obj)\n",
    "\n",
    "    for tar_seed in tar_seeds:\n",
    "        latents.append(\n",
    "            init_latent(\n",
    "                model=pipe, device_name=device, dtype=torch_dtype, seed=tar_seed\n",
    "            )\n",
    "        )\n",
    "\n",
    "    latents = torch.cat(latents, dim=0)\n",
    "\n",
    "    images = pipe(\n",
    "        prompt=ref_prompt,\n",
    "        guidance_scale=7,\n",
    "        latents=latents,\n",
    "        num_images_per_prompt=len(tar_seeds),\n",
    "        target_prompt=inf_prompt,\n",
    "        use_inf_negative_prompt=False,\n",
    "        use_advanced_sampling=False,\n",
    "        use_prompt_as_null=True,\n",
    "        image=real_img,\n",
    "    )[0]\n",
    "    # [real image, fake1, fake2, ... ]\n",
    "    save_path = os.path.join(args.results_dir, \"{}_{}.png\".format(style_name, tar_obj))\n",
    "\n",
    "    n_row = 1\n",
    "    n_col = len(tar_seeds)\n",
    "    grid = create_image_grid(images, n_row, n_col)\n",
    "\n",
    "    grid.save(save_path)\n",
    "    print(f\"saved to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
